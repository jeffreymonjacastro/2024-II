{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rWA1ylJiiX1"
   },
   "source": [
    "# Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3y5zMCBxvfnV"
   },
   "source": [
    "## Dataset Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwTBzpM-UPWi",
    "outputId": "9e91cffa-9eec-4382-87b8-aa871bdd1256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDS59IltpVv1",
    "outputId": "4fb82e2a-ec98-422f-f18b-9f8d79bd18fd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MVZbnMXYpZfj"
   },
   "outputs": [],
   "source": [
    "# path = \"/content/drive/Shareddrives/G5/project-4-sentiment-classification/\"\n",
    "path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "rLST8-d4eGRp",
    "outputId": "38411464-fcb1-4e2d-eceb-0097f721aeeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message label\n",
       "0  I saw this movie in NEW York city. I was waiti...   neg\n",
       "1  This is a German film from 1974 that is someth...   neg\n",
       "2  I attempted watching this movie twice and even...   neg\n",
       "3  On his birthday a small boys tells his mother ...   neg\n",
       "4  The person who wrote the review \"enough with t...   pos"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(path + \"train.csv\")\n",
    "test_data = pd.read_csv(path + \"test.csv\")\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sCcDJzY-Af1",
    "outputId": "03f79824-a97d-41df-f60e-000c1ceaddde"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gnji7ChJ-w8m"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "A8XnKwdU-x4k"
   },
   "outputs": [],
   "source": [
    "train_data['tokens'] = train_data['message'].apply(preprocess_text)\n",
    "# test_data_preprocessed = test_data['message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "G9Ttcl8XL5CT",
    "outputId": "193ecffd-4ddb-4af0-ca19-f1a910320191"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>neg</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>neg</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>pos</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...   neg   \n",
       "1  This is a German film from 1974 that is someth...   neg   \n",
       "2  I attempted watching this movie twice and even...   neg   \n",
       "3  On his birthday a small boys tells his mother ...   neg   \n",
       "4  The person who wrote the review \"enough with t...   pos   \n",
       "\n",
       "                                              tokens  \n",
       "0  saw movie new york city waiting bus next morni...  \n",
       "1  german film something woman come castle beyond...  \n",
       "2  attempted watching movie twice even fast forwa...  \n",
       "3  birthday small boy tell mother son want go hom...  \n",
       "4  person wrote review enough sweating spitting a...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D12g6cMvLX7z",
    "outputId": "c6d6c829-07b3-4a8d-d937-b1fd9afa25d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1421\n"
     ]
    }
   ],
   "source": [
    "max_len = max(train_data['tokens'].apply(lambda text: len(text.split())))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MRhmX59vHeJw"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['label'] = label_encoder.fit_transform(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...      0   \n",
       "1  This is a German film from 1974 that is someth...      0   \n",
       "2  I attempted watching this movie twice and even...      0   \n",
       "3  On his birthday a small boys tells his mother ...      0   \n",
       "4  The person who wrote the review \"enough with t...      1   \n",
       "\n",
       "                                              tokens  \n",
       "0  saw movie new york city waiting bus next morni...  \n",
       "1  german film something woman come castle beyond...  \n",
       "2  attempted watching movie twice even fast forwa...  \n",
       "3  birthday small boy tell mother son want go hom...  \n",
       "4  person wrote review enough sweating spitting a...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etSydSCaCslj"
   },
   "outputs": [],
   "source": [
    "# train_data_preprocessed = pd.concat([train_data_preprocessed, train_data['label']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaMoYAcw0-xl"
   },
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "86vli-ic0-L-"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = train_data['tokens'].apply(lambda x: x.split()).to_list()\n",
    "\n",
    "word2vec = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "arNGArWIEQqA"
   },
   "outputs": [],
   "source": [
    "def sentence_to_vectors(sentence, model, vector_size=100):\n",
    "    vectors = []\n",
    "    for word in sentence.split():\n",
    "        if word in model.wv:\n",
    "            vectors.append(model.wv[word])\n",
    "        else:\n",
    "            vectors.append([0] * vector_size)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "rWsYJ_YgPtL2"
   },
   "outputs": [],
   "source": [
    "train_data['vectors'] = train_data['tokens'].apply(lambda x: sentence_to_vectors(x, word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZaraXLUESpgq"
   },
   "outputs": [],
   "source": [
    "train_data['vectors'] = train_data['vectors'].apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rslEICv8Qi1f"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Reduce max_len\n",
    "def pad_sentences(vectors, max_len, vector_size=100):\n",
    "    if len(vectors) > max_len:\n",
    "        vectors = vectors[:max_len]\n",
    "    else:\n",
    "        padding = np.zeros((max_len - len(vectors), vector_size))\n",
    "        vectors = np.vstack([vectors, padding])\n",
    "    return torch.tensor(vectors, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Lmnl4g5NSn-r"
   },
   "outputs": [],
   "source": [
    "train_data['padded_vectors'] = train_data['vectors'].apply(lambda x: pad_sentences(np.array(x), max_len, word2vec.vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(path + 'train_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.stack(train_data['padded_vectors'].tolist())\n",
    "y = torch.tensor(train_data['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwUTDpPRPNX4"
   },
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvQlUMtUG22n",
    "outputId": "c4cdadbe-a3ce-429c-d360-3474db356c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2), lowercase=True)\n",
    "X_train = vectorizer.fit_transform(train['message'])\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EOzcWHgHRtY",
    "outputId": "960ad6d0-3fd3-41c6-99a7-6683a6cb28cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3867)\t0.24998872545018597\n",
      "  (0, 2912)\t0.11242199684392602\n",
      "  (0, 3060)\t0.11927197024321219\n",
      "  (0, 4985)\t0.18355799824437657\n",
      "  (0, 823)\t0.16809344373899543\n",
      "  (0, 4786)\t0.18993407919273902\n",
      "  (0, 628)\t0.2422105409252342\n",
      "  (0, 2899)\t0.4412603841129476\n",
      "  (0, 4802)\t0.11037667839688935\n",
      "  (0, 4784)\t0.17858376429652753\n",
      "  (0, 4867)\t0.15373758799338144\n",
      "  (0, 4280)\t0.17687764294688155\n",
      "  (0, 4940)\t0.13281789522993748\n",
      "  (0, 1631)\t0.06024820855862076\n",
      "  (0, 2542)\t0.10119673959126436\n",
      "  (0, 288)\t0.1921119299981152\n",
      "  (0, 801)\t0.22849793750841113\n",
      "  (0, 4227)\t0.16953796180828518\n",
      "  (0, 4974)\t0.10351508061438297\n",
      "  (0, 1028)\t0.18627142632603821\n",
      "  (0, 4229)\t0.23101054228387058\n",
      "  (0, 3869)\t0.19210182023899758\n",
      "  (0, 3061)\t0.18640875225904535\n",
      "  (0, 4986)\t0.242499998479016\n",
      "  (0, 4941)\t0.20947163233508553\n",
      "  :\t:\n",
      "  (24998, 3241)\t0.22383527690408916\n",
      "  (24998, 3048)\t0.20681969959007346\n",
      "  (24998, 3049)\t0.21747283241125134\n",
      "  (24998, 3686)\t0.2001612762260745\n",
      "  (24998, 3820)\t0.20659747344733098\n",
      "  (24998, 4343)\t0.20108981007208032\n",
      "  (24998, 152)\t0.22899800737451736\n",
      "  (24999, 2912)\t0.1525892711902319\n",
      "  (24999, 1903)\t0.20824651245891104\n",
      "  (24999, 1471)\t0.22005599024281886\n",
      "  (24999, 1326)\t0.24315916923052702\n",
      "  (24999, 4628)\t0.1888519038854902\n",
      "  (24999, 1822)\t0.16423482886850274\n",
      "  (24999, 48)\t0.13836732580292938\n",
      "  (24999, 2880)\t0.1815848869877712\n",
      "  (24999, 832)\t0.19527020023278707\n",
      "  (24999, 4261)\t0.11415500193792914\n",
      "  (24999, 1467)\t0.27448298727903103\n",
      "  (24999, 4916)\t0.2044803715289331\n",
      "  (24999, 3880)\t0.23898920000158133\n",
      "  (24999, 834)\t0.3612379556698347\n",
      "  (24999, 4774)\t0.3029445307741556\n",
      "  (24999, 1624)\t0.2202565287495391\n",
      "  (24999, 1905)\t0.30013811024898207\n",
      "  (24999, 2882)\t0.35319586116445445\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
