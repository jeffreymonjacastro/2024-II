{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rWA1ylJiiX1"
   },
   "source": [
    "# Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3y5zMCBxvfnV"
   },
   "source": [
    "## Dataset Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwTBzpM-UPWi",
    "outputId": "8c4156ea-0c7f-42cf-fb50-fc72a1946716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "# print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDS59IltpVv1",
    "outputId": "87ba2cfc-4f11-4abc-9117-3b934810849c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MVZbnMXYpZfj"
   },
   "outputs": [],
   "source": [
    "path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "rLST8-d4eGRp",
    "outputId": "c97e16da-2c68-43dc-9f9c-dd243570184e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message label\n",
       "0  I saw this movie in NEW York city. I was waiti...   neg\n",
       "1  This is a German film from 1974 that is someth...   neg\n",
       "2  I attempted watching this movie twice and even...   neg\n",
       "3  On his birthday a small boys tells his mother ...   neg\n",
       "4  The person who wrote the review \"enough with t...   pos"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(path + \"train.csv\")\n",
    "test_data = pd.read_csv(path + \"test.csv\")\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sCcDJzY-Af1",
    "outputId": "46a64c89-832b-417f-d022-4a32e1bbbaba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gnji7ChJ-w8m"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "A8XnKwdU-x4k"
   },
   "outputs": [],
   "source": [
    "train_data['tokens'] = train_data['message'].apply(preprocess_text)\n",
    "test_data['tokens'] = test_data['message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "G9Ttcl8XL5CT",
    "outputId": "e810a9cf-9d10-492f-ee6b-d45b6b94155d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>neg</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>neg</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>pos</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...   neg   \n",
       "1  This is a German film from 1974 that is someth...   neg   \n",
       "2  I attempted watching this movie twice and even...   neg   \n",
       "3  On his birthday a small boys tells his mother ...   neg   \n",
       "4  The person who wrote the review \"enough with t...   pos   \n",
       "\n",
       "                                              tokens  \n",
       "0  saw movie new york city waiting bus next morni...  \n",
       "1  german film something woman come castle beyond...  \n",
       "2  attempted watching movie twice even fast forwa...  \n",
       "3  birthday small boy tell mother son want go hom...  \n",
       "4  person wrote review enough sweating spitting a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6q__P3GnqXLm",
    "outputId": "3b5db1f1-866c-4b02-c9b9-207fbdb0421a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acclaimed Argentine horror director Emilio Vie...</td>\n",
       "      <td>acclaimed argentine horror director emilio vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't know if it's fair for me to review thi...</td>\n",
       "      <td>know fair review fan gratuitous violence never...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The only good thing about Persepolis is the sh...</td>\n",
       "      <td>good thing persepolis shadow created german an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I completely forgot that I'd seen this within ...</td>\n",
       "      <td>completely forgot seen within couple day prett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B. Kennedy tried to make a sequel by exaggerat...</td>\n",
       "      <td>kennedy tried make sequel exaggerating gargant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Acclaimed Argentine horror director Emilio Vie...   \n",
       "1  I don't know if it's fair for me to review thi...   \n",
       "2  The only good thing about Persepolis is the sh...   \n",
       "3  I completely forgot that I'd seen this within ...   \n",
       "4  B. Kennedy tried to make a sequel by exaggerat...   \n",
       "\n",
       "                                              tokens  \n",
       "0  acclaimed argentine horror director emilio vie...  \n",
       "1  know fair review fan gratuitous violence never...  \n",
       "2  good thing persepolis shadow created german an...  \n",
       "3  completely forgot seen within couple day prett...  \n",
       "4  kennedy tried make sequel exaggerating gargant...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D12g6cMvLX7z",
    "outputId": "c3608260-fc25-4509-9185-685715aaf065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 1421\n",
      "Mean length: 119\n"
     ]
    }
   ],
   "source": [
    "max_len = max(train_data['tokens'].apply(lambda text: len(text.split())))\n",
    "mean_len = int(round(np.mean(train_data['tokens'].apply(lambda text: len(text.split())))))\n",
    "\n",
    "print(f'Max length: {max_len}')\n",
    "print(f'Mean length: {mean_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "MRhmX59vHeJw"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_data['label'] = label_encoder.fit_transform(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "W2tqRFbHsVxB",
    "outputId": "b4dec639-83c8-427d-a12a-a393ca8f6706"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectors</th>\n",
       "      <th>padded_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "      <td>[[-0.19189617, -0.028692013, -0.32174656, -0.2...</td>\n",
       "      <td>[[tensor(-0.1919), tensor(-0.0287), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "      <td>[[-0.47960114, 0.5583763, -0.1370875, -0.44397...</td>\n",
       "      <td>[[tensor(-0.4796), tensor(0.5584), tensor(-0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "      <td>[[-0.13749087, 0.18824586, 0.024570609, 0.1324...</td>\n",
       "      <td>[[tensor(-0.1375), tensor(0.1882), tensor(0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "      <td>[[0.117996156, 0.49617633, -0.494434, -0.36352...</td>\n",
       "      <td>[[tensor(0.1180), tensor(0.4962), tensor(-0.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "      <td>[[0.048615, 0.3482453, -0.36405486, 0.4022355,...</td>\n",
       "      <td>[[tensor(0.0486), tensor(0.3482), tensor(-0.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...      0   \n",
       "1  This is a German film from 1974 that is someth...      0   \n",
       "2  I attempted watching this movie twice and even...      0   \n",
       "3  On his birthday a small boys tells his mother ...      0   \n",
       "4  The person who wrote the review \"enough with t...      1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  saw movie new york city waiting bus next morni...   \n",
       "1  german film something woman come castle beyond...   \n",
       "2  attempted watching movie twice even fast forwa...   \n",
       "3  birthday small boy tell mother son want go hom...   \n",
       "4  person wrote review enough sweating spitting a...   \n",
       "\n",
       "                                             vectors  \\\n",
       "0  [[-0.19189617, -0.028692013, -0.32174656, -0.2...   \n",
       "1  [[-0.47960114, 0.5583763, -0.1370875, -0.44397...   \n",
       "2  [[-0.13749087, 0.18824586, 0.024570609, 0.1324...   \n",
       "3  [[0.117996156, 0.49617633, -0.494434, -0.36352...   \n",
       "4  [[0.048615, 0.3482453, -0.36405486, 0.4022355,...   \n",
       "\n",
       "                                      padded_vectors  \n",
       "0  [[tensor(-0.1919), tensor(-0.0287), tensor(-0....  \n",
       "1  [[tensor(-0.4796), tensor(0.5584), tensor(-0.1...  \n",
       "2  [[tensor(-0.1375), tensor(0.1882), tensor(0.02...  \n",
       "3  [[tensor(0.1180), tensor(0.4962), tensor(-0.49...  \n",
       "4  [[tensor(0.0486), tensor(0.3482), tensor(-0.36...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaMoYAcw0-xl"
   },
   "source": [
    "### Word Embedding (Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "86vli-ic0-L-"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = train_data['tokens'].apply(lambda x: x.split()).to_list()\n",
    "\n",
    "word2vec = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "s5HSgFtRc25m"
   },
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "word2vec.save(path + \"word2vec_model\")\n",
    "\n",
    "# Cargar el modelo\n",
    "# word2vec = Word2Vec.load(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "arNGArWIEQqA"
   },
   "outputs": [],
   "source": [
    "def sentence_to_vectors(sentence, model, vector_size=100):\n",
    "    vectors = []\n",
    "    for word in sentence.split():\n",
    "        if word in model.wv:\n",
    "            vectors.append(model.wv[word])\n",
    "        else:\n",
    "            vectors.append([0] * vector_size)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rWsYJ_YgPtL2"
   },
   "outputs": [],
   "source": [
    "train_data['vectors'] = train_data['tokens'].apply(lambda x: sentence_to_vectors(x, word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ZaraXLUESpgq"
   },
   "outputs": [],
   "source": [
    "train_data['vectors'] = train_data['vectors'].apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectors</th>\n",
       "      <th>padded_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "      <td>[[-0.19189617, -0.028692013, -0.32174656, -0.2...</td>\n",
       "      <td>[[tensor(-0.1919), tensor(-0.0287), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "      <td>[[-0.47960114, 0.5583763, -0.1370875, -0.44397...</td>\n",
       "      <td>[[tensor(-0.4796), tensor(0.5584), tensor(-0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "      <td>[[-0.13749087, 0.18824586, 0.024570609, 0.1324...</td>\n",
       "      <td>[[tensor(-0.1375), tensor(0.1882), tensor(0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "      <td>[[0.117996156, 0.49617633, -0.494434, -0.36352...</td>\n",
       "      <td>[[tensor(0.1180), tensor(0.4962), tensor(-0.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "      <td>[[0.048615, 0.3482453, -0.36405486, 0.4022355,...</td>\n",
       "      <td>[[tensor(0.0486), tensor(0.3482), tensor(-0.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...      0   \n",
       "1  This is a German film from 1974 that is someth...      0   \n",
       "2  I attempted watching this movie twice and even...      0   \n",
       "3  On his birthday a small boys tells his mother ...      0   \n",
       "4  The person who wrote the review \"enough with t...      1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  saw movie new york city waiting bus next morni...   \n",
       "1  german film something woman come castle beyond...   \n",
       "2  attempted watching movie twice even fast forwa...   \n",
       "3  birthday small boy tell mother son want go hom...   \n",
       "4  person wrote review enough sweating spitting a...   \n",
       "\n",
       "                                             vectors  \\\n",
       "0  [[-0.19189617, -0.028692013, -0.32174656, -0.2...   \n",
       "1  [[-0.47960114, 0.5583763, -0.1370875, -0.44397...   \n",
       "2  [[-0.13749087, 0.18824586, 0.024570609, 0.1324...   \n",
       "3  [[0.117996156, 0.49617633, -0.494434, -0.36352...   \n",
       "4  [[0.048615, 0.3482453, -0.36405486, 0.4022355,...   \n",
       "\n",
       "                                      padded_vectors  \n",
       "0  [[tensor(-0.1919), tensor(-0.0287), tensor(-0....  \n",
       "1  [[tensor(-0.4796), tensor(0.5584), tensor(-0.1...  \n",
       "2  [[tensor(-0.1375), tensor(0.1882), tensor(0.02...  \n",
       "3  [[tensor(0.1180), tensor(0.4962), tensor(-0.49...  \n",
       "4  [[tensor(0.0486), tensor(0.3482), tensor(-0.36...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rslEICv8Qi1f"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def pad_sentences(vectors, max_len, vector_size=100):\n",
    "    if len(vectors) > max_len:\n",
    "        vectors = vectors[:max_len]\n",
    "    else:\n",
    "        padding = np.zeros((max_len - len(vectors), vector_size))\n",
    "        vectors = np.vstack([vectors, padding])\n",
    "    return torch.tensor(vectors, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Lmnl4g5NSn-r"
   },
   "outputs": [],
   "source": [
    "train_data['padded_vectors'] = train_data['vectors'].apply(lambda x: pad_sentences(np.array(x), mean_len, word2vec.vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectors</th>\n",
       "      <th>padded_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "      <td>[[-0.19189617, -0.028692013, -0.32174656, -0.2...</td>\n",
       "      <td>[[tensor(-0.1919), tensor(-0.0287), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "      <td>[[-0.47960114, 0.5583763, -0.1370875, -0.44397...</td>\n",
       "      <td>[[tensor(-0.4796), tensor(0.5584), tensor(-0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "      <td>[[-0.13749087, 0.18824586, 0.024570609, 0.1324...</td>\n",
       "      <td>[[tensor(-0.1375), tensor(0.1882), tensor(0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "      <td>[[0.117996156, 0.49617633, -0.494434, -0.36352...</td>\n",
       "      <td>[[tensor(0.1180), tensor(0.4962), tensor(-0.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "      <td>[[0.048615, 0.3482453, -0.36405486, 0.4022355,...</td>\n",
       "      <td>[[tensor(0.0486), tensor(0.3482), tensor(-0.36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...      0   \n",
       "1  This is a German film from 1974 that is someth...      0   \n",
       "2  I attempted watching this movie twice and even...      0   \n",
       "3  On his birthday a small boys tells his mother ...      0   \n",
       "4  The person who wrote the review \"enough with t...      1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  saw movie new york city waiting bus next morni...   \n",
       "1  german film something woman come castle beyond...   \n",
       "2  attempted watching movie twice even fast forwa...   \n",
       "3  birthday small boy tell mother son want go hom...   \n",
       "4  person wrote review enough sweating spitting a...   \n",
       "\n",
       "                                             vectors  \\\n",
       "0  [[-0.19189617, -0.028692013, -0.32174656, -0.2...   \n",
       "1  [[-0.47960114, 0.5583763, -0.1370875, -0.44397...   \n",
       "2  [[-0.13749087, 0.18824586, 0.024570609, 0.1324...   \n",
       "3  [[0.117996156, 0.49617633, -0.494434, -0.36352...   \n",
       "4  [[0.048615, 0.3482453, -0.36405486, 0.4022355,...   \n",
       "\n",
       "                                      padded_vectors  \n",
       "0  [[tensor(-0.1919), tensor(-0.0287), tensor(-0....  \n",
       "1  [[tensor(-0.4796), tensor(0.5584), tensor(-0.1...  \n",
       "2  [[tensor(-0.1375), tensor(0.1882), tensor(0.02...  \n",
       "3  [[tensor(0.1180), tensor(0.4962), tensor(-0.49...  \n",
       "4  [[tensor(0.0486), tensor(0.3482), tensor(-0.36...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data['tokens'][2].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6o7ThqbldFd6"
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(path + \"train_data_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwUTDpPRPNX4"
   },
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvQlUMtUG22n",
    "outputId": "c0655997-db39-492d-a4d8-cc0ad389c106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2), lowercase=True)\n",
    "X_tfidf = vectorizer.fit_transform(train_data['tokens']).toarray()\n",
    "\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo0qVeOpeymp"
   },
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xIc2jdQee3rX"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.unsqueeze(1)  # (batch_size, 1, input_dim)\n",
    "        _, (hidden, _) = self.lstm(x)  # Solo usamos el estado oculto final\n",
    "        hidden = hidden[-1]  # Si hay múltiples capas, tomamos la última\n",
    "        out = self.fc(hidden)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "sdcTNZDmipLM"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, kernel_size=3, stride=1, padding=1, layers=1, batch_norm=False, dropout=False, mlp_layers=2, activation='relu', output_type='sigmoid'):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "        in_channels = input_dim\n",
    "        out_channels = output_dim\n",
    "\n",
    "        # Seleccionar la función de activación\n",
    "        if activation == 'relu':\n",
    "            self.activation_fn = nn.ReLU()\n",
    "        elif activation == 'leaky_relu':\n",
    "            self.activation_fn = nn.LeakyReLU(0.1)\n",
    "        elif activation == 'tanh':\n",
    "            self.activation_fn = nn.Tanh()\n",
    "        else:\n",
    "            raise ValueError(f\"Activation {activation} not supported\")\n",
    "\n",
    "        # Seleccionar el tipo de salida\n",
    "        if output_type == 'sigmoid':\n",
    "            self.output_fn = nn.Sigmoid()\n",
    "        elif output_type == 'linear':\n",
    "            self.output_fn = nn.Identity()  # Salida sin función de activación\n",
    "        else:\n",
    "            raise ValueError(f\"Output type {output_type} not supported\")\n",
    "\n",
    "        # Capas convolucionales\n",
    "        for i in range(layers):\n",
    "            self.conv_blocks.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=padding\n",
    "                    ),\n",
    "                    self.activation_fn,\n",
    "                    nn.BatchNorm1d(out_channels) if batch_norm else nn.Identity(),\n",
    "                    nn.Dropout(0.3) if dropout else nn.Identity(),\n",
    "                    nn.MaxPool1d(kernel_size=2)\n",
    "                )\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "            out_channels *= 2\n",
    "\n",
    "        # Capas MLP configurables\n",
    "        self.mlp_layers = mlp_layers\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Reorganiza las dimensiones a [batch_size, input_dim, sequence_length]\n",
    "\n",
    "        # Pasar por las capas convolucionales\n",
    "        for block in self.conv_blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        # Asegurar que las capas MLP se inicialicen correctamente\n",
    "        if not self.fc_layers:\n",
    "            final_output_dim = x.size(1) * x.size(2)  # canales_finales * longitud_final\n",
    "            input_dim = final_output_dim\n",
    "            for _ in range(self.mlp_layers - 1):\n",
    "                self.fc_layers.append(nn.Linear(input_dim, input_dim // 2))\n",
    "                self.fc_layers.append(self.activation_fn)\n",
    "                input_dim //= 2\n",
    "            self.fc_layers.append(nn.Linear(input_dim, 1))  # Última capa\n",
    "            self.fc_layers = nn.ModuleList(self.fc_layers).to(x.device)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Aplana para la capa completamente conectada\n",
    "\n",
    "        # Pasar por las capas MLP\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.output_fn(x)  # Aplicar la función de salida seleccionada\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCGCEbOKuUAS"
   },
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "exxGuedMesMb"
   },
   "outputs": [],
   "source": [
    "X = torch.stack(train_data['padded_vectors'].tolist())\n",
    "y = torch.tensor(train_data['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 119, 100])\n",
      "torch.Size([25000])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpbBj5Mze83H",
    "outputId": "0612168b-e0d0-4fdb-ca1e-3488081bb157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.664803598499298\n",
      "Epoch 2/20, Loss: 0.6548450751304626\n",
      "Epoch 3/20, Loss: 0.6547182178020478\n",
      "Epoch 4/20, Loss: 0.4216099470734596\n",
      "Epoch 5/20, Loss: 0.33870818737745284\n",
      "Epoch 6/20, Loss: 0.3217929998636246\n",
      "Epoch 7/20, Loss: 0.3096813480257988\n",
      "Epoch 8/20, Loss: 0.3064695837497711\n",
      "Epoch 9/20, Loss: 0.2974167529821396\n",
      "Epoch 10/20, Loss: 0.29189534715414045\n",
      "Epoch 11/20, Loss: 0.2886060152411461\n",
      "Epoch 12/20, Loss: 0.3598038797259331\n",
      "Epoch 13/20, Loss: 0.3541577285885811\n",
      "Epoch 14/20, Loss: 0.26870052126646043\n",
      "Epoch 15/20, Loss: 0.2629007907927036\n",
      "Epoch 16/20, Loss: 0.2556140527009964\n",
      "Epoch 17/20, Loss: 0.2469605266213417\n",
      "Epoch 18/20, Loss: 0.2379913802653551\n",
      "Epoch 19/20, Loss: 0.22532076367139817\n",
      "Epoch 20/20, Loss: 0.21644155465364456\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Crear un dataset de PyTorch\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "train_size = int(0.8 * len(dataset))  # 80% para entrenamiento\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "input_dim = word2vec.vector_size\n",
    "hidden_dim = 128\n",
    "output_dim = 2\n",
    "model = LSTMClassifier(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 20\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        # inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.long()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "GUe8JKbqjAJi",
    "outputId": "d732124a-7f1e-4e01-81fb-399ebfbe00fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=2, activation=relu, output_type=sigmoid\n",
      "Accuracy: 86.98%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=2, activation=relu, output_type=linear\n",
      "Accuracy: 85.28%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=2, activation=leaky_relu, output_type=sigmoid\n",
      "Accuracy: 86.50%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=2, activation=leaky_relu, output_type=linear\n",
      "Accuracy: 85.02%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=2, activation=tanh, output_type=sigmoid\n",
      "Accuracy: 86.80%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=2, activation=tanh, output_type=linear\n",
      "Accuracy: 85.52%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=3, activation=relu, output_type=sigmoid\n",
      "Accuracy: 86.38%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=3, activation=relu, output_type=linear\n",
      "Accuracy: 86.72%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=3, activation=leaky_relu, output_type=sigmoid\n",
      "Accuracy: 86.48%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=3, activation=leaky_relu, output_type=linear\n",
      "Accuracy: 86.58%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=3, activation=tanh, output_type=sigmoid\n",
      "Accuracy: 86.16%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=3, activation=tanh, output_type=linear\n",
      "Accuracy: 86.52%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=4, activation=relu, output_type=sigmoid\n",
      "Accuracy: 86.76%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=4, activation=relu, output_type=linear\n",
      "Accuracy: 86.90%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=4, activation=leaky_relu, output_type=sigmoid\n",
      "Accuracy: 86.66%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=4, activation=leaky_relu, output_type=linear\n",
      "Accuracy: 85.96%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=4, activation=tanh, output_type=sigmoid\n",
      "Accuracy: 86.08%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=4, activation=tanh, output_type=linear\n",
      "Accuracy: 86.36%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=5, activation=relu, output_type=sigmoid\n",
      "Accuracy: 85.68%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=5, activation=relu, output_type=linear\n",
      "Accuracy: 80.68%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=5, activation=leaky_relu, output_type=sigmoid\n",
      "Accuracy: 85.74%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=5, activation=leaky_relu, output_type=linear\n",
      "Accuracy: 87.00%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=5, activation=tanh, output_type=sigmoid\n",
      "Accuracy: 85.92%\n",
      "Training with layers=3, batch_norm=True, dropout=True, mlp_layers=5, activation=tanh, output_type=linear\n",
      "Accuracy: 77.72%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=2, activation=relu, output_type=sigmoid\n",
      "Accuracy: 84.88%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=2, activation=relu, output_type=linear\n",
      "Accuracy: 81.14%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=2, activation=leaky_relu, output_type=sigmoid\n",
      "Accuracy: 80.92%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=2, activation=leaky_relu, output_type=linear\n",
      "Accuracy: 82.84%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=2, activation=tanh, output_type=sigmoid\n",
      "Accuracy: 82.32%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=2, activation=tanh, output_type=linear\n",
      "Accuracy: 82.74%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=3, activation=relu, output_type=sigmoid\n",
      "Accuracy: 84.90%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=3, activation=relu, output_type=linear\n",
      "Accuracy: 83.60%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=3, activation=leaky_relu, output_type=sigmoid\n",
      "Accuracy: 82.56%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=3, activation=leaky_relu, output_type=linear\n",
      "Accuracy: 83.86%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=3, activation=tanh, output_type=sigmoid\n",
      "Accuracy: 84.60%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=3, activation=tanh, output_type=linear\n",
      "Accuracy: 81.74%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=4, activation=relu, output_type=sigmoid\n",
      "Accuracy: 84.72%\n",
      "Training with layers=3, batch_norm=True, dropout=False, mlp_layers=4, activation=relu, output_type=linear\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import torch\n",
    "\n",
    "# Asegúrate de que estás utilizando la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Parámetros del experimento\n",
    "layers_range = range(3, 6)  # De 3 a 6 capas convolucionales\n",
    "batch_norm_options = [True, False]\n",
    "dropout_options = [True, False]\n",
    "mlp_layer_range = range(2, 6)  # De 2 a 3 capas en el MLP final\n",
    "activations = ['relu', 'leaky_relu', 'tanh']  # Funciones de activación\n",
    "output_types = ['sigmoid', 'linear']  # Tipos de salida\n",
    "\n",
    "# Generar todas las combinaciones de parámetros\n",
    "parameter_combinations = list(product(layers_range, batch_norm_options, dropout_options, mlp_layer_range, activations, output_types))\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop por cada combinación de parámetros\n",
    "for layers, batch_norm, dropout, mlp_layers, activation, output_type in parameter_combinations:\n",
    "    print(f\"Training with layers={layers}, batch_norm={batch_norm}, dropout={dropout}, mlp_layers={mlp_layers}, activation={activation}, output_type={output_type}\")\n",
    "\n",
    "    # Inicializar modelo\n",
    "    model = CNN(input_dim=word2vec.vector_size, output_dim=16, layers=layers, batch_norm=batch_norm, dropout=dropout, mlp_layers=mlp_layers, activation=activation, output_type=output_type)\n",
    "    model = model.to(device)  # Mueve el modelo a la GPU\n",
    "\n",
    "    # Configurar criterio de pérdida y optimizador\n",
    "    criterion = nn.MSELoss()  # Pérdida para regresión\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Entrenamiento\n",
    "    epochs = 20\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            labels = labels.float().to(device)  # Mueve las etiquetas a la GPU\n",
    "            inputs = inputs.float().to(device)  # Mueve los datos a la GPU\n",
    "            outputs = model(inputs).squeeze()  # Asegúrate de que los outputs sean del mismo tamaño que las etiquetas\n",
    "            loss = criterion(outputs, labels)  # Calcula la pérdida\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Actualización del optimizador\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.float().to(device)  # Mueve los datos a la GPU\n",
    "            labels = labels.to(device).float()  # Asegúrate de que las etiquetas sean float\n",
    "            outputs = model(inputs).squeeze()\n",
    "            predicted = (outputs >= 0.5).float()  # Predicciones binarizadas\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Guardar resultados\n",
    "    results.append({\n",
    "        \"layers\": layers,\n",
    "        \"batch_norm\": batch_norm,\n",
    "        \"dropout\": dropout,\n",
    "        \"mlp_layers\": mlp_layers,\n",
    "        \"activation\": activation,\n",
    "        \"output_type\": output_type,\n",
    "        \"accuracy\": accuracy\n",
    "    })\n",
    "\n",
    "# Ordenar resultados por precisión\n",
    "sorted_results = sorted(results, key=lambda x: x[\"accuracy\"], reverse=True)\n",
    "\n",
    "# Imprimir mejores resultados\n",
    "print(\"\\nTop Results:\")\n",
    "for result in sorted_results[:5]:  # Los 5 mejores\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcmV5NPwihcV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMIGaaaOfIr6",
    "outputId": "6519b762-83b7-4d1e-baec-f0e92da05bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.04%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihn6AzBMuYlA"
   },
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEylC93Xusp3"
   },
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X_tfidf, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(train_data['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq3H6z-8vVo6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Crear un dataset de PyTorch\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "train_size = int(0.8 * len(dataset))  # 80% para entrenamiento\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E293IZsVvpOO"
   },
   "outputs": [],
   "source": [
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "input_dim = 5000  # TF-IDF max_features\n",
    "hidden_dim = 128  # Número de unidades ocultas\n",
    "output_dim = 2    # Número de clases\n",
    "model = LSTMClassifier(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9r63FjhvwKC"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
