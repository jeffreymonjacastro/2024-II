{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rWA1ylJiiX1"
   },
   "source": [
    "# Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3y5zMCBxvfnV"
   },
   "source": [
    "## Dataset Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xwTBzpM-UPWi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDS59IltpVv1",
    "outputId": "4a9afc46-3fc7-491b-80db-b44daede3e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MVZbnMXYpZfj"
   },
   "outputs": [],
   "source": [
    "# path = \"/content/drive/Shareddrives/G5/project-4-sentiment-classification/\"\n",
    "path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "rLST8-d4eGRp",
    "outputId": "a0bdc166-1a68-4fb8-b24f-edf66972a8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "(25000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message label\n",
       "0  I saw this movie in NEW York city. I was waiti...   neg\n",
       "1  This is a German film from 1974 that is someth...   neg\n",
       "2  I attempted watching this movie twice and even...   neg\n",
       "3  On his birthday a small boys tells his mother ...   neg\n",
       "4  The person who wrote the review \"enough with t...   pos"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(path + \"train.csv\")\n",
    "test_data = pd.read_csv(path + \"test.csv\")\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5fSJwi5eQxH"
   },
   "source": [
    "Adding nltk libraries for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sCcDJzY-Af1",
    "outputId": "5b26a6a3-05fc-45a7-b50e-79c422824a7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\jeffr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxIuH4bFeXZF"
   },
   "source": [
    "Function that tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "gnji7ChJ-w8m"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYslT6rOeaJV"
   },
   "source": [
    "Add the tokenized text to a new column in train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tokens'] = train_data['message'].apply(preprocess_text)\n",
    "test_data['tokens'] = test_data['message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "G9Ttcl8XL5CT",
    "outputId": "2f4e6ed2-ac1e-4645-d29f-77194c7740bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>neg</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>neg</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>pos</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...   neg   \n",
       "1  This is a German film from 1974 that is someth...   neg   \n",
       "2  I attempted watching this movie twice and even...   neg   \n",
       "3  On his birthday a small boys tells his mother ...   neg   \n",
       "4  The person who wrote the review \"enough with t...   pos   \n",
       "\n",
       "                                              tokens  \n",
       "0  saw movie new york city waiting bus next morni...  \n",
       "1  german film something woman come castle beyond...  \n",
       "2  attempted watching movie twice even fast forwa...  \n",
       "3  birthday small boy tell mother son want go hom...  \n",
       "4  person wrote review enough sweating spitting a...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6q__P3GnqXLm",
    "outputId": "16e00127-086b-453f-dbd2-83e6650c0f83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acclaimed Argentine horror director Emilio Vie...</td>\n",
       "      <td>acclaimed argentine horror director emilio vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't know if it's fair for me to review thi...</td>\n",
       "      <td>know fair review fan gratuitous violence never...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The only good thing about Persepolis is the sh...</td>\n",
       "      <td>good thing persepolis shadow created german an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I completely forgot that I'd seen this within ...</td>\n",
       "      <td>completely forgot seen within couple day prett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B. Kennedy tried to make a sequel by exaggerat...</td>\n",
       "      <td>kennedy tried make sequel exaggerating gargant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Acclaimed Argentine horror director Emilio Vie...   \n",
       "1  I don't know if it's fair for me to review thi...   \n",
       "2  The only good thing about Persepolis is the sh...   \n",
       "3  I completely forgot that I'd seen this within ...   \n",
       "4  B. Kennedy tried to make a sequel by exaggerat...   \n",
       "\n",
       "                                              tokens  \n",
       "0  acclaimed argentine horror director emilio vie...  \n",
       "1  know fair review fan gratuitous violence never...  \n",
       "2  good thing persepolis shadow created german an...  \n",
       "3  completely forgot seen within couple day prett...  \n",
       "4  kennedy tried make sequel exaggerating gargant...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AywXOm_mef9K"
   },
   "source": [
    "Encoding the labels (0: pos, 1: neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "MRhmX59vHeJw"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()  \n",
    "train_data['label'] = label_encoder.fit_transform(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "W2tqRFbHsVxB",
    "outputId": "47acbe75-8885-4b02-8698-f991327d8744"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...      0   \n",
       "1  This is a German film from 1974 that is someth...      0   \n",
       "2  I attempted watching this movie twice and even...      0   \n",
       "3  On his birthday a small boys tells his mother ...      0   \n",
       "4  The person who wrote the review \"enough with t...      1   \n",
       "\n",
       "                                              tokens  \n",
       "0  saw movie new york city waiting bus next morni...  \n",
       "1  german film something woman come castle beyond...  \n",
       "2  attempted watching movie twice even fast forwa...  \n",
       "3  birthday small boy tell mother son want go hom...  \n",
       "4  person wrote review enough sweating spitting a...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaMoYAcw0-xl"
   },
   "source": [
    "### Word Embedding (Word2Vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-F_DbqUYek_k"
   },
   "source": [
    "Method to feature text extraction. The class Word2Vec is a neural network that is trained with all the tokens of the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "86vli-ic0-L-"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = train_data['tokens'].apply(lambda x: x.split()).to_list()\n",
    "\n",
    "word2vec = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJMFPyqqfIcE"
   },
   "source": [
    "Training the word2vec model for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "UdBWwWe4cVzQ"
   },
   "outputs": [],
   "source": [
    "sentences_test = test_data['tokens'].apply(lambda x: x.split()).to_list()\n",
    "\n",
    "word2vec_test = Word2Vec(sentences=sentences_test, vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTSb9UeHfyrN"
   },
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "s5HSgFtRc25m"
   },
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "word2vec.save(path + \"word2vec_train_model\")\n",
    "word2vec_test.save(path + \"word2vec_test_model\")\n",
    "\n",
    "# Cargar el modelo\n",
    "# word2vec = Word2Vec.load(\"word2vec_test_model\")\n",
    "# word2vec_test = Word2Vec.load(\"word2vec_test_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t71RnKuxfz-u"
   },
   "source": [
    "Function that maps all the tokens of each row with its corresponding feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "arNGArWIEQqA"
   },
   "outputs": [],
   "source": [
    "def sentence_to_vectors(sentence, model, vector_size=100):\n",
    "    vectors = []\n",
    "    for word in sentence.split():\n",
    "        if word in model.wv:\n",
    "            vectors.append(model.wv[word])\n",
    "        else:\n",
    "            vectors.append([0] * vector_size)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 1421\n",
      "Mean length: 119\n"
     ]
    }
   ],
   "source": [
    "max_len = max(train_data['tokens'].apply(lambda text: len(text.split())))\n",
    "mean_len = round(np.mean(train_data['tokens'].apply(lambda text: len(text.split()))))\n",
    "\n",
    "print(f'Max length: {max_len}')\n",
    "print(f'Mean length: {mean_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFJIYZZAf_tW"
   },
   "source": [
    "Saving the feature vectors in a new column and normalizing the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "rWsYJ_YgPtL2"
   },
   "outputs": [],
   "source": [
    "train_data['vectors'] = train_data['tokens'].apply(lambda x: sentence_to_vectors(x, word2vec))\n",
    "test_data['vectors'] = test_data['tokens'].apply(lambda x: sentence_to_vectors(x, word2vec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "      <td>[[0.09326658, 0.10232236, -0.5063842, -0.41179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "      <td>[[-0.32682985, 0.27852288, -0.18955359, -0.486...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "      <td>[[-0.03599018, -0.006980085, 0.29945117, 0.421...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "      <td>[[0.06317541, 0.4016989, -0.64858943, -0.37955...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "      <td>[[-0.074894525, 0.2501159, -0.14314865, 0.4145...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...      0   \n",
       "1  This is a German film from 1974 that is someth...      0   \n",
       "2  I attempted watching this movie twice and even...      0   \n",
       "3  On his birthday a small boys tells his mother ...      0   \n",
       "4  The person who wrote the review \"enough with t...      1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  saw movie new york city waiting bus next morni...   \n",
       "1  german film something woman come castle beyond...   \n",
       "2  attempted watching movie twice even fast forwa...   \n",
       "3  birthday small boy tell mother son want go hom...   \n",
       "4  person wrote review enough sweating spitting a...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [[0.09326658, 0.10232236, -0.5063842, -0.41179...  \n",
       "1  [[-0.32682985, 0.27852288, -0.18955359, -0.486...  \n",
       "2  [[-0.03599018, -0.006980085, 0.29945117, 0.421...  \n",
       "3  [[0.06317541, 0.4016989, -0.64858943, -0.37955...  \n",
       "4  [[-0.074894525, 0.2501159, -0.14314865, 0.4145...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qtTrhn7irhG"
   },
   "source": [
    "Normalize the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "pAG8kmIqiq2r"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_data['vectors'] = train_data['vectors'].apply(lambda x: scaler.fit_transform(x))\n",
    "test_data['vectors'] = test_data['vectors'].apply(lambda x: scaler.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "xLyZizOJki2X",
    "outputId": "6a90d79c-f969-4857-dc05-628647a885c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectors</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "      <td>[[0.7613983973953181, 0.37214972655208, 0.0183...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "      <td>[[0.35351079310495453, 0.5796608186564652, 0.3...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "      <td>[[0.6356779305619685, 0.25589794030384716, 0.8...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "      <td>[[0.5706008552945276, 0.826410954348949, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "      <td>[[0.7012216743999262, 0.6190995233686329, 0.41...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...      0   \n",
       "1  This is a German film from 1974 that is someth...      0   \n",
       "2  I attempted watching this movie twice and even...      0   \n",
       "3  On his birthday a small boys tells his mother ...      0   \n",
       "4  The person who wrote the review \"enough with t...      1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  saw movie new york city waiting bus next morni...   \n",
       "1  german film something woman come castle beyond...   \n",
       "2  attempted watching movie twice even fast forwa...   \n",
       "3  birthday small boy tell mother son want go hom...   \n",
       "4  person wrote review enough sweating spitting a...   \n",
       "\n",
       "                                             vectors  \\\n",
       "0  [[0.7613983973953181, 0.37214972655208, 0.0183...   \n",
       "1  [[0.35351079310495453, 0.5796608186564652, 0.3...   \n",
       "2  [[0.6356779305619685, 0.25589794030384716, 0.8...   \n",
       "3  [[0.5706008552945276, 0.826410954348949, 0.0, ...   \n",
       "4  [[0.7012216743999262, 0.6190995233686329, 0.41...   \n",
       "\n",
       "                                               tfidf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "SATg6P-2ho_w",
    "outputId": "ee8ae0d2-79d5-4fd9-f805-8c814a89858d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acclaimed Argentine horror director Emilio Vie...</td>\n",
       "      <td>acclaimed argentine horror director emilio vie...</td>\n",
       "      <td>[[0.2517718570337515, 0.4632532813656189, 0.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't know if it's fair for me to review thi...</td>\n",
       "      <td>know fair review fan gratuitous violence never...</td>\n",
       "      <td>[[0.414121311590642, 0.19043247456763368, 0.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The only good thing about Persepolis is the sh...</td>\n",
       "      <td>good thing persepolis shadow created german an...</td>\n",
       "      <td>[[0.5413249950897219, 0.661586795968182, 0.496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I completely forgot that I'd seen this within ...</td>\n",
       "      <td>completely forgot seen within couple day prett...</td>\n",
       "      <td>[[0.5895263409703918, 0.4695384655903072, 0.61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B. Kennedy tried to make a sequel by exaggerat...</td>\n",
       "      <td>kennedy tried make sequel exaggerating gargant...</td>\n",
       "      <td>[[0.6394430032299151, 0.4203580853765238, 0.41...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Acclaimed Argentine horror director Emilio Vie...   \n",
       "1  I don't know if it's fair for me to review thi...   \n",
       "2  The only good thing about Persepolis is the sh...   \n",
       "3  I completely forgot that I'd seen this within ...   \n",
       "4  B. Kennedy tried to make a sequel by exaggerat...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  acclaimed argentine horror director emilio vie...   \n",
       "1  know fair review fan gratuitous violence never...   \n",
       "2  good thing persepolis shadow created german an...   \n",
       "3  completely forgot seen within couple day prett...   \n",
       "4  kennedy tried make sequel exaggerating gargant...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [[0.2517718570337515, 0.4632532813656189, 0.56...  \n",
       "1  [[0.414121311590642, 0.19043247456763368, 0.53...  \n",
       "2  [[0.5413249950897219, 0.661586795968182, 0.496...  \n",
       "3  [[0.5895263409703918, 0.4695384655903072, 0.61...  \n",
       "4  [[0.6394430032299151, 0.4203580853765238, 0.41...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwUTDpPRPNX4"
   },
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method uses the TF-IDF algorithm to extract features from the text data according to the frequency and importance of each word in the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "WvQlUMtUG22n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n",
      "(25000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2), lowercase=True)\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data['tokens']).toarray()\n",
    "X_test_tfidf = vectorizer.transform(test_data['tokens']).toarray()\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.02946132 0.03679143 0.05483793 0.05497426 0.05987872\n",
      " 0.06179367 0.06449474 0.06589665 0.06796903 0.07032864 0.07417273\n",
      " 0.07567818 0.07883546 0.07951672 0.08184364 0.08205103 0.08275188\n",
      " 0.08418937 0.08430638 0.08566853 0.08757607 0.08869587 0.08991665\n",
      " 0.09313713 0.09370546 0.09634121 0.09914383 0.09950548 0.09982102\n",
      " 0.10428246 0.11119358 0.1127536  0.11350027 0.11473618 0.11605794\n",
      " 0.1177484  0.11960372 0.11975421 0.1218273  0.1239646  0.12724801\n",
      " 0.14180076 0.17514435 0.18733408 0.21296585 0.23041254 0.23861249\n",
      " 0.31767079 0.32054147 0.44773859]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(np.unique(X_train_tfidf[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['tfidf'] = list(X_train_tfidf)\n",
    "test_data['tfidf'] = list(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectors</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I saw this movie in NEW York city. I was waiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>saw movie new york city waiting bus next morni...</td>\n",
       "      <td>[[0.7635628566251051, 0.43391089419340095, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a German film from 1974 that is someth...</td>\n",
       "      <td>0</td>\n",
       "      <td>german film something woman come castle beyond...</td>\n",
       "      <td>[[0.2417061183155192, 0.5087659396431822, 0.38...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I attempted watching this movie twice and even...</td>\n",
       "      <td>0</td>\n",
       "      <td>attempted watching movie twice even fast forwa...</td>\n",
       "      <td>[[0.6134121699946612, 0.29120593555177465, 0.6...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On his birthday a small boys tells his mother ...</td>\n",
       "      <td>0</td>\n",
       "      <td>birthday small boy tell mother son want go hom...</td>\n",
       "      <td>[[0.6755493421548452, 0.8097028871608277, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The person who wrote the review \"enough with t...</td>\n",
       "      <td>1</td>\n",
       "      <td>person wrote review enough sweating spitting a...</td>\n",
       "      <td>[[0.7727563516445829, 0.5337629343724954, 0.40...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  label  \\\n",
       "0  I saw this movie in NEW York city. I was waiti...      0   \n",
       "1  This is a German film from 1974 that is someth...      0   \n",
       "2  I attempted watching this movie twice and even...      0   \n",
       "3  On his birthday a small boys tells his mother ...      0   \n",
       "4  The person who wrote the review \"enough with t...      1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  saw movie new york city waiting bus next morni...   \n",
       "1  german film something woman come castle beyond...   \n",
       "2  attempted watching movie twice even fast forwa...   \n",
       "3  birthday small boy tell mother son want go hom...   \n",
       "4  person wrote review enough sweating spitting a...   \n",
       "\n",
       "                                             vectors  \\\n",
       "0  [[0.7635628566251051, 0.43391089419340095, 0.0...   \n",
       "1  [[0.2417061183155192, 0.5087659396431822, 0.38...   \n",
       "2  [[0.6134121699946612, 0.29120593555177465, 0.6...   \n",
       "3  [[0.6755493421548452, 0.8097028871608277, 0.0,...   \n",
       "4  [[0.7727563516445829, 0.5337629343724954, 0.40...   \n",
       "\n",
       "                                               tfidf  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "6o7ThqbldFd6"
   },
   "outputs": [],
   "source": [
    "train_data.to_csv(path + \"train_data_preprocessed.csv\", index=False)\n",
    "test_data.to_csv(path + \"test_data_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D12g6cMvLX7z",
    "outputId": "e6360249-b2eb-4d5b-a44f-97205d97c541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 1421\n",
      "Mean length: 119\n"
     ]
    }
   ],
   "source": [
    "max_len = max(train_data['tokens'].apply(lambda text: len(text.split())))\n",
    "mean_len = np.mean(train_data['tokens'].apply(lambda text: len(text.split())))\n",
    "\n",
    "print(f'Max length: {max_len}')\n",
    "print(f'Mean length: {round(mean_len)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npkaEX4zgFhL"
   },
   "source": [
    "This function truncate each row that have more than `mean_len` words or adds a zeroes vector for each row that have less than `mean_len` words. Transforms the data into torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rslEICv8Qi1f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_len = int(mean_len)\n",
    "\n",
    "def pad_sentences(vectors, max_len, vector_size=100):\n",
    "    if len(vectors) > max_len:\n",
    "        vectors = vectors[:max_len]\n",
    "    else:\n",
    "        padding = np.zeros((max_len - len(vectors), vector_size))\n",
    "        vectors = np.vstack([vectors, padding])\n",
    "    return vectors.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Lmnl4g5NSn-r"
   },
   "outputs": [],
   "source": [
    "train_data['tensor'] = train_data['vectors'].apply(lambda x: pad_sentences(x, mean_len, word2vec.vector_size))\n",
    "test_data['tensor'] = test_data['vectors'].apply(lambda x: pad_sentences(x, mean_len, word2vec_test.vector_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qo0qVeOpeymp"
   },
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCGCEbOKuUAS"
   },
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exxGuedMesMb"
   },
   "outputs": [],
   "source": [
    "X = torch.stack(train_data['padded_vectors'].tolist())\n",
    "y = torch.tensor(train_data['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpbBj5Mze83H",
    "outputId": "de99b575-aff9-471b-9647-bd289a5abbd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.6716709010601044\n",
      "Epoch 2/20, Loss: 0.6755033177375793\n",
      "Epoch 3/20, Loss: 0.6814942306518554\n",
      "Epoch 4/20, Loss: 0.5333627909660339\n",
      "Epoch 5/20, Loss: 0.3804534206867218\n",
      "Epoch 6/20, Loss: 0.3511510826826096\n",
      "Epoch 7/20, Loss: 0.33705521540641786\n",
      "Epoch 8/20, Loss: 0.32991589548587796\n",
      "Epoch 9/20, Loss: 0.32034432963728904\n",
      "Epoch 10/20, Loss: 0.31565868777036665\n",
      "Epoch 11/20, Loss: 0.31078529708385466\n",
      "Epoch 12/20, Loss: 0.30663199263811114\n",
      "Epoch 13/20, Loss: 0.29701457860469815\n",
      "Epoch 14/20, Loss: 0.2948506070137024\n",
      "Epoch 15/20, Loss: 0.2878551222205162\n",
      "Epoch 16/20, Loss: 0.281745883500576\n",
      "Epoch 17/20, Loss: 0.27399428837299344\n",
      "Epoch 18/20, Loss: 0.266418141579628\n",
      "Epoch 19/20, Loss: 0.25981831710338593\n",
      "Epoch 20/20, Loss: 0.24420327085256577\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Crear un dataset de PyTorch\n",
    "dataset = TensorDataset(X, y)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "train_size = int(0.8 * len(dataset))  # 80% para entrenamiento\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "input_dim = word2vec.vector_size\n",
    "hidden_dim = 128\n",
    "output_dim = 2\n",
    "model = LSTMClassifier(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 20\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        # inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMIGaaaOfIr6",
    "outputId": "e3ec45cd-517b-4377-89d3-43abdb96a05f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.34%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihn6AzBMuYlA"
   },
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEylC93Xusp3"
   },
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X_tfidf, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(train_data['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq3H6z-8vVo6"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# Crear un dataset de PyTorch\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "train_size = int(0.8 * len(dataset))  # 80% para entrenamiento\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "E293IZsVvpOO",
    "outputId": "ca9ecfe3-594f-40c7-96f4-83380da1358d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.2088390737771988\n",
      "Epoch 2/10, Loss: 0.3516410291194916\n",
      "Epoch 3/10, Loss: 0.29308614134788513\n",
      "Epoch 4/10, Loss: 0.1689564734697342\n",
      "Epoch 5/10, Loss: 0.14249277114868164\n",
      "Epoch 6/10, Loss: 0.06334441900253296\n",
      "Epoch 7/10, Loss: 0.08491527289152145\n",
      "Epoch 8/10, Loss: 0.062416449189186096\n",
      "Epoch 9/10, Loss: 0.07067599147558212\n",
      "Epoch 10/10, Loss: 0.03959621489048004\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo, la función de pérdida y el optimizador\n",
    "input_dim = 5000  # TF-IDF max_features\n",
    "hidden_dim = 128  # Número de unidades ocultas\n",
    "output_dim = 2    # Número de clases\n",
    "model = LSTMClassifier(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9r63FjhvwKC",
    "outputId": "ef8ba290-6f69-4895-8fbb-4cb5b7c6dd94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.72%\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
